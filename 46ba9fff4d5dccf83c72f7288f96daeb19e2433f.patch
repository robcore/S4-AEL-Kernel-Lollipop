From 46ba9fff4d5dccf83c72f7288f96daeb19e2433f Mon Sep 17 00:00:00 2001
From: robcore <robpatershuk@gmail.com>
Date: Mon, 2 May 2016 21:53:59 -0600
Subject: [PATCH] a bunch of freezable blocking call upgrades, also autosleep

---
 7483b4a4d9abf9dcf1ffe6e805ead2847ec3264e.patch | 514 +++++++++++++++++++++++++
 Documentation/ABI/testing/sysfs-power          |  17 +
 Documentation/power/freezing-of-tasks.txt      |   5 +
 drivers/base/power/wakeup.c                    |  32 +-
 fs/cifs/transport.c                            |   2 +-
 fs/nfs/inode.c                                 |   2 +-
 fs/nfs/nfs3proc.c                              |   2 +-
 fs/nfs/nfs4proc.c                              |   4 +-
 include/linux/freezer.h                        | 146 ++++++-
 include/linux/sched.h                          |   1 +
 include/linux/suspend.h                        |  13 +-
 kernel/exit.c                                  |   4 +-
 kernel/freezer.c                               |   2 +-
 kernel/power/Kconfig                           |   8 +
 kernel/power/Makefile                          |   1 +
 kernel/power/autosleep.c                       | 123 ++++++
 kernel/power/main.c                            | 155 ++++++--
 kernel/power/power.h                           |  18 +
 kernel/power/process.c                         |  11 +-
 mm/fremap.c                                    |  24 +-
 mm/vmscan.c                                    |   3 +-
 net/sunrpc/sched.c                             |   2 +-
 22 files changed, 1000 insertions(+), 89 deletions(-)
 create mode 100644 7483b4a4d9abf9dcf1ffe6e805ead2847ec3264e.patch
 create mode 100644 kernel/power/autosleep.c

diff --git a/7483b4a4d9abf9dcf1ffe6e805ead2847ec3264e.patch b/7483b4a4d9abf9dcf1ffe6e805ead2847ec3264e.patch
new file mode 100644
index 0000000..065cd5e
--- /dev/null
+++ b/7483b4a4d9abf9dcf1ffe6e805ead2847ec3264e.patch
@@ -0,0 +1,514 @@
+From 7483b4a4d9abf9dcf1ffe6e805ead2847ec3264e Mon Sep 17 00:00:00 2001
+From: "Rafael J. Wysocki" <rjw@sisk.pl>
+Date: Sun, 29 Apr 2012 22:53:22 +0200
+Subject: [PATCH] PM / Sleep: Implement opportunistic sleep, v2
+
+Introduce a mechanism by which the kernel can trigger global
+transitions to a sleep state chosen by user space if there are no
+active wakeup sources.
+
+It consists of a new sysfs attribute, /sys/power/autosleep, that
+can be written one of the strings returned by reads from
+/sys/power/state, an ordered workqueue and a work item carrying out
+the "suspend" operations.  If a string representing the system's
+sleep state is written to /sys/power/autosleep, the work item
+triggering transitions to that state is queued up and it requeues
+itself after every execution until user space writes "off" to
+/sys/power/autosleep.
+
+That work item enables the detection of wakeup events using the
+functions already defined in drivers/base/power/wakeup.c (with one
+small modification) and calls either pm_suspend(), or hibernate() to
+put the system into a sleep state.  If a wakeup event is reported
+while the transition is in progress, it will abort the transition and
+the "system suspend" work item will be queued up again.
+
+Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
+Acked-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
+Reviewed-by: NeilBrown <neilb@suse.de>
+---
+ Documentation/ABI/testing/sysfs-power |  17 +++++
+ drivers/base/power/wakeup.c           |  34 +++++-----
+ include/linux/suspend.h               |  13 +++-
+ kernel/power/Kconfig                  |   8 +++
+ kernel/power/Makefile                 |   1 +
+ kernel/power/autosleep.c              | 123 ++++++++++++++++++++++++++++++++++
+ kernel/power/main.c                   | 119 ++++++++++++++++++++++++++------
+ kernel/power/power.h                  |  18 +++++
+ 8 files changed, 298 insertions(+), 35 deletions(-)
+ create mode 100644 kernel/power/autosleep.c
+
+diff --git a/Documentation/ABI/testing/sysfs-power b/Documentation/ABI/testing/sysfs-power
+index b464d12..237c735 100644
+--- a/Documentation/ABI/testing/sysfs-power
++++ b/Documentation/ABI/testing/sysfs-power
+@@ -172,3 +172,20 @@ Description:
+ 
+ 		Reading from this file will display the current value, which is
+ 		set to 1 MB by default.
++
++What:		/sys/power/autosleep
++Date:		April 2012
++Contact:	Rafael J. Wysocki <rjw@sisk.pl>
++Description:
++		The /sys/power/autosleep file can be written one of the strings
++		returned by reads from /sys/power/state.  If that happens, a
++		work item attempting to trigger a transition of the system to
++		the sleep state represented by that string is queued up.  This
++		attempt will only succeed if there are no active wakeup sources
++		in the system at that time.  After every execution, regardless
++		of whether or not the attempt to put the system to sleep has
++		succeeded, the work item requeues itself until user space
++		writes "off" to /sys/power/autosleep.
++
++		Reading from this file causes the last string successfully
++		written to it to be returned.
+diff --git a/drivers/base/power/wakeup.c b/drivers/base/power/wakeup.c
+index 1132799..cf1706d 100644
+--- a/drivers/base/power/wakeup.c
++++ b/drivers/base/power/wakeup.c
+@@ -660,29 +660,33 @@ bool pm_wakeup_pending(void)
+ /**
+  * pm_get_wakeup_count - Read the number of registered wakeup events.
+  * @count: Address to store the value at.
++ * @block: Whether or not to block.
+  *
+- * Store the number of registered wakeup events at the address in @count.  Block
+- * if the current number of wakeup events being processed is nonzero.
++ * Store the number of registered wakeup events at the address in @count.  If
++ * @block is set, block until the current number of wakeup events being
++ * processed is zero.
+  *
+- * Return 'false' if the wait for the number of wakeup events being processed to
+- * drop down to zero has been interrupted by a signal (and the current number
+- * of wakeup events being processed is still nonzero).  Otherwise return 'true'.
++ * Return 'false' if the current number of wakeup events being processed is
++ * nonzero.  Otherwise return 'true'.
+  */
+-bool pm_get_wakeup_count(unsigned int *count)
++bool pm_get_wakeup_count(unsigned int *count, bool block)
+ {
+ 	unsigned int cnt, inpr;
+-	DEFINE_WAIT(wait);
+ 
+-	for (;;) {
+-		prepare_to_wait(&wakeup_count_wait_queue, &wait,
+-				TASK_INTERRUPTIBLE);
+-		split_counters(&cnt, &inpr);
+-		if (inpr == 0 || signal_pending(current))
+-			break;
++	if (block) {
++		DEFINE_WAIT(wait);
++
++		for (;;) {
++			prepare_to_wait(&wakeup_count_wait_queue, &wait,
++					TASK_INTERRUPTIBLE);
++			split_counters(&cnt, &inpr);
++			if (inpr == 0 || signal_pending(current))
++				break;
+ 
+-		schedule();
++			schedule();
++		}
++		finish_wait(&wakeup_count_wait_queue, &wait);
+ 	}
+-	finish_wait(&wakeup_count_wait_queue, &wait);
+ 
+ 	split_counters(&cnt, &inpr);
+ 	*count = cnt;
+diff --git a/include/linux/suspend.h b/include/linux/suspend.h
+index ac1c114..76b7ec7 100644
+--- a/include/linux/suspend.h
++++ b/include/linux/suspend.h
+@@ -356,7 +356,7 @@ extern int unregister_pm_notifier(struct notifier_block *nb);
+ extern bool events_check_enabled;
+ 
+ extern bool pm_wakeup_pending(void);
+-extern bool pm_get_wakeup_count(unsigned int *count);
++extern bool pm_get_wakeup_count(unsigned int *count, bool block);
+ extern bool pm_save_wakeup_count(unsigned int count);
+ 
+ static inline void lock_system_sleep(void)
+@@ -407,6 +407,17 @@ static inline void unlock_system_sleep(void) {}
+ 
+ #endif /* !CONFIG_PM_SLEEP */
+ 
++#ifdef CONFIG_PM_AUTOSLEEP
++
++/* kernel/power/autosleep.c */
++void queue_up_suspend_work(void);
++
++#else /* !CONFIG_PM_AUTOSLEEP */
++
++static inline void queue_up_suspend_work(void) {}
++
++#endif /* !CONFIG_PM_AUTOSLEEP */
++
+ #ifdef CONFIG_ARCH_SAVE_PAGE_KEYS
+ /*
+  * The ARCH_SAVE_PAGE_KEYS functions can be used by an architecture
+diff --git a/kernel/power/Kconfig b/kernel/power/Kconfig
+index deb5461..6794708 100644
+--- a/kernel/power/Kconfig
++++ b/kernel/power/Kconfig
+@@ -103,6 +103,14 @@ config PM_SLEEP_SMP
+ 	select HOTPLUG
+ 	select HOTPLUG_CPU
+ 
++config PM_AUTOSLEEP
++	bool "Opportunistic sleep"
++	depends on PM_SLEEP
++	default n
++	---help---
++	Allow the kernel to trigger a system transition into a global sleep
++	state automatically whenever there are no active wakeup sources.
++
+ config PM_RUNTIME
+ 	bool "Run-time PM core functionality"
+ 	depends on !IA64_HP_SIM
+diff --git a/kernel/power/Makefile b/kernel/power/Makefile
+index 66d808e..010b2f7 100644
+--- a/kernel/power/Makefile
++++ b/kernel/power/Makefile
+@@ -9,5 +9,6 @@ obj-$(CONFIG_SUSPEND)		+= suspend.o
+ obj-$(CONFIG_PM_TEST_SUSPEND)	+= suspend_test.o
+ obj-$(CONFIG_HIBERNATION)	+= hibernate.o snapshot.o swap.o user.o \
+ 				   block_io.o
++obj-$(CONFIG_PM_AUTOSLEEP)	+= autosleep.o
+ 
+ obj-$(CONFIG_MAGIC_SYSRQ)	+= poweroff.o
+diff --git a/kernel/power/autosleep.c b/kernel/power/autosleep.c
+new file mode 100644
+index 0000000..42348e3
+--- /dev/null
++++ b/kernel/power/autosleep.c
+@@ -0,0 +1,123 @@
++/*
++ * kernel/power/autosleep.c
++ *
++ * Opportunistic sleep support.
++ *
++ * Copyright (C) 2012 Rafael J. Wysocki <rjw@sisk.pl>
++ */
++
++#include <linux/device.h>
++#include <linux/mutex.h>
++#include <linux/pm_wakeup.h>
++
++#include "power.h"
++
++static suspend_state_t autosleep_state;
++static struct workqueue_struct *autosleep_wq;
++/*
++ * Note: it is only safe to mutex_lock(&autosleep_lock) if a wakeup_source
++ * is active, otherwise a deadlock with try_to_suspend() is possible.
++ * Alternatively mutex_lock_interruptible() can be used.  This will then fail
++ * if an auto_sleep cycle tries to freeze processes.
++ */
++static DEFINE_MUTEX(autosleep_lock);
++static struct wakeup_source *autosleep_ws;
++
++static void try_to_suspend(struct work_struct *work)
++{
++	unsigned int initial_count, final_count;
++
++	if (!pm_get_wakeup_count(&initial_count, true))
++		goto out;
++
++	mutex_lock(&autosleep_lock);
++
++	if (!pm_save_wakeup_count(initial_count)) {
++		mutex_unlock(&autosleep_lock);
++		goto out;
++	}
++
++	if (autosleep_state == PM_SUSPEND_ON) {
++		mutex_unlock(&autosleep_lock);
++		return;
++	}
++	if (autosleep_state >= PM_SUSPEND_MAX)
++		hibernate();
++	else
++		pm_suspend(autosleep_state);
++
++	mutex_unlock(&autosleep_lock);
++
++	if (!pm_get_wakeup_count(&final_count, false))
++		goto out;
++
++	/*
++	 * If the wakeup occured for an unknown reason, wait to prevent the
++	 * system from trying to suspend and waking up in a tight loop.
++	 */
++	if (final_count == initial_count)
++		schedule_timeout_uninterruptible(HZ / 2);
++
++ out:
++	queue_up_suspend_work();
++}
++
++static DECLARE_WORK(suspend_work, try_to_suspend);
++
++void queue_up_suspend_work(void)
++{
++	if (!work_pending(&suspend_work) && autosleep_state > PM_SUSPEND_ON)
++		queue_work(autosleep_wq, &suspend_work);
++}
++
++suspend_state_t pm_autosleep_state(void)
++{
++	return autosleep_state;
++}
++
++int pm_autosleep_lock(void)
++{
++	return mutex_lock_interruptible(&autosleep_lock);
++}
++
++void pm_autosleep_unlock(void)
++{
++	mutex_unlock(&autosleep_lock);
++}
++
++int pm_autosleep_set_state(suspend_state_t state)
++{
++
++#ifndef CONFIG_HIBERNATION
++	if (state >= PM_SUSPEND_MAX)
++		return -EINVAL;
++#endif
++
++	__pm_stay_awake(autosleep_ws);
++
++	mutex_lock(&autosleep_lock);
++
++	autosleep_state = state;
++
++	__pm_relax(autosleep_ws);
++
++	if (state > PM_SUSPEND_ON)
++		queue_up_suspend_work();
++
++	mutex_unlock(&autosleep_lock);
++	return 0;
++}
++
++int __init pm_autosleep_init(void)
++{
++	autosleep_ws = wakeup_source_register("autosleep");
++	if (!autosleep_ws)
++		return -ENOMEM;
++
++	autosleep_wq = alloc_ordered_workqueue("autosleep", 0);
++	if (autosleep_wq)
++		return 0;
++
++	wakeup_source_unregister(autosleep_ws);
++	return -ENOMEM;
++}
+diff --git a/kernel/power/main.c b/kernel/power/main.c
+index 1c12581..ba6a564 100644
+--- a/kernel/power/main.c
++++ b/kernel/power/main.c
+@@ -269,8 +269,7 @@ static ssize_t state_show(struct kobject *kobj, struct kobj_attribute *attr,
+ 	return (s - buf);
+ }
+ 
+-static ssize_t state_store(struct kobject *kobj, struct kobj_attribute *attr,
+-			   const char *buf, size_t n)
++static suspend_state_t decode_state(const char *buf, size_t n)
+ {
+ #ifdef CONFIG_SUSPEND
+ 	suspend_state_t state = PM_SUSPEND_STANDBY;
+@@ -278,27 +277,48 @@ static ssize_t state_store(struct kobject *kobj, struct kobj_attribute *attr,
+ #endif
+ 	char *p;
+ 	int len;
+-	int error = -EINVAL;
+ 
+ 	p = memchr(buf, '\n', n);
+ 	len = p ? p - buf : n;
+ 
+-	/* First, check if we are requested to hibernate */
+-	if (len == 4 && !strncmp(buf, "disk", len)) {
+-		error = hibernate();
+-		goto Exit;
+-	}
++	/* Check hibernation first. */
++	if (len == 4 && !strncmp(buf, "disk", len))
++		return PM_SUSPEND_MAX;
+ 
+ #ifdef CONFIG_SUSPEND
+-	for (s = &pm_states[state]; state < PM_SUSPEND_MAX; s++, state++) {
+-		if (*s && len == strlen(*s) && !strncmp(buf, *s, len)) {
+-			error = pm_suspend(state);
+-			break;
+-		}
+-	}
++	for (s = &pm_states[state]; state < PM_SUSPEND_MAX; s++, state++)
++		if (*s && len == strlen(*s) && !strncmp(buf, *s, len))
++			return state;
+ #endif
+ 
+- Exit:
++	return PM_SUSPEND_ON;
++}
++
++static ssize_t state_store(struct kobject *kobj, struct kobj_attribute *attr,
++			   const char *buf, size_t n)
++{
++	suspend_state_t state;
++	int error;
++
++	error = pm_autosleep_lock();
++	if (error)
++		return error;
++
++	if (pm_autosleep_state() > PM_SUSPEND_ON) {
++		error = -EBUSY;
++		goto out;
++	}
++
++	state = decode_state(buf, n);
++	if (state < PM_SUSPEND_MAX)
++		error = pm_suspend(state);
++	else if (state == PM_SUSPEND_MAX)
++		error = hibernate();
++	else
++		error = -EINVAL;
++
++ out:
++	pm_autosleep_unlock();
+ 	return error ? error : n;
+ }
+ 
+@@ -339,7 +359,8 @@ static ssize_t wakeup_count_show(struct kobject *kobj,
+ {
+ 	unsigned int val;
+ 
+-	return pm_get_wakeup_count(&val) ? sprintf(buf, "%u\n", val) : -EINTR;
++	return pm_get_wakeup_count(&val, true) ?
++		sprintf(buf, "%u\n", val) : -EINTR;
+ }
+ 
+ static ssize_t wakeup_count_store(struct kobject *kobj,
+@@ -347,15 +368,69 @@ static ssize_t wakeup_count_store(struct kobject *kobj,
+ 				const char *buf, size_t n)
+ {
+ 	unsigned int val;
++	int error;
++
++	error = pm_autosleep_lock();
++	if (error)
++		return error;
+ 
++	if (pm_autosleep_state() > PM_SUSPEND_ON) {
++		error = -EBUSY;
++		goto out;
++	}
++
++	error = -EINVAL;
+ 	if (sscanf(buf, "%u", &val) == 1) {
+ 		if (pm_save_wakeup_count(val))
+-			return n;
++			error = n;
+ 	}
+-	return -EINVAL;
++
++ out:
++	pm_autosleep_unlock();
++	return error;
+ }
+ 
+ power_attr(wakeup_count);
++
++#ifdef CONFIG_PM_AUTOSLEEP
++static ssize_t autosleep_show(struct kobject *kobj,
++			      struct kobj_attribute *attr,
++			      char *buf)
++{
++	suspend_state_t state = pm_autosleep_state();
++
++	if (state == PM_SUSPEND_ON)
++		return sprintf(buf, "off\n");
++
++#ifdef CONFIG_SUSPEND
++	if (state < PM_SUSPEND_MAX)
++		return sprintf(buf, "%s\n", valid_state(state) ?
++						pm_states[state] : "error");
++#endif
++#ifdef CONFIG_HIBERNATION
++	return sprintf(buf, "disk\n");
++#else
++	return sprintf(buf, "error");
++#endif
++}
++
++static ssize_t autosleep_store(struct kobject *kobj,
++			       struct kobj_attribute *attr,
++			       const char *buf, size_t n)
++{
++	suspend_state_t state = decode_state(buf, n);
++	int error;
++
++	if (state == PM_SUSPEND_ON
++	    && !(strncmp(buf, "off", 3) && strncmp(buf, "off\n", 4)))
++		return -EINVAL;
++
++	error = pm_autosleep_set_state(state);
++	return error ? error : n;
++}
++
++power_attr(autosleep);
++#endif /* CONFIG_PM_AUTOSLEEP */
+ #endif /* CONFIG_PM_SLEEP */
+ 
+ #ifdef CONFIG_PM_TRACE
+@@ -409,6 +484,9 @@ static struct attribute * g[] = {
+ #ifdef CONFIG_PM_SLEEP
+ 	&pm_async_attr.attr,
+ 	&wakeup_count_attr.attr,
++#ifdef CONFIG_PM_AUTOSLEEP
++	&autosleep_attr.attr,
++#endif
+ #ifdef CONFIG_PM_DEBUG
+ 	&pm_test_attr.attr,
+ #endif
+@@ -444,7 +522,10 @@ static int __init pm_init(void)
+ 	power_kobj = kobject_create_and_add("power", NULL);
+ 	if (!power_kobj)
+ 		return -ENOMEM;
+-	return sysfs_create_group(power_kobj, &attr_group);
++	error = sysfs_create_group(power_kobj, &attr_group);
++	if (error)
++		return error;
++	return pm_autosleep_init();
+ }
+ 
+ core_initcall(pm_init);
+diff --git a/kernel/power/power.h b/kernel/power/power.h
+index 98f3622..4cf80fa 100644
+--- a/kernel/power/power.h
++++ b/kernel/power/power.h
+@@ -264,3 +264,21 @@ static inline void suspend_thaw_processes(void)
+ {
+ }
+ #endif
++
++#ifdef CONFIG_PM_AUTOSLEEP
++
++/* kernel/power/autosleep.c */
++extern int pm_autosleep_init(void);
++extern int pm_autosleep_lock(void);
++extern void pm_autosleep_unlock(void);
++extern suspend_state_t pm_autosleep_state(void);
++extern int pm_autosleep_set_state(suspend_state_t state);
++
++#else /* !CONFIG_PM_AUTOSLEEP */
++
++static inline int pm_autosleep_init(void) { return 0; }
++static inline int pm_autosleep_lock(void) { return 0; }
++static inline void pm_autosleep_unlock(void) {}
++static inline suspend_state_t pm_autosleep_state(void) { return PM_SUSPEND_ON; }
++
++#endif /* !CONFIG_PM_AUTOSLEEP */
diff --git a/Documentation/ABI/testing/sysfs-power b/Documentation/ABI/testing/sysfs-power
index b464d12..237c735 100755
--- a/Documentation/ABI/testing/sysfs-power
+++ b/Documentation/ABI/testing/sysfs-power
@@ -172,3 +172,20 @@ Description:
 
 		Reading from this file will display the current value, which is
 		set to 1 MB by default.
+
+What:		/sys/power/autosleep
+Date:		April 2012
+Contact:	Rafael J. Wysocki <rjw@sisk.pl>
+Description:
+		The /sys/power/autosleep file can be written one of the strings
+		returned by reads from /sys/power/state.  If that happens, a
+		work item attempting to trigger a transition of the system to
+		the sleep state represented by that string is queued up.  This
+		attempt will only succeed if there are no active wakeup sources
+		in the system at that time.  After every execution, regardless
+		of whether or not the attempt to put the system to sleep has
+		succeeded, the work item requeues itself until user space
+		writes "off" to /sys/power/autosleep.
+
+		Reading from this file causes the last string successfully
+		written to it to be returned.
diff --git a/Documentation/power/freezing-of-tasks.txt b/Documentation/power/freezing-of-tasks.txt
index 6ec291e..85894d8 100755
--- a/Documentation/power/freezing-of-tasks.txt
+++ b/Documentation/power/freezing-of-tasks.txt
@@ -223,3 +223,8 @@ since they ask the freezer to skip freezing this task, since it is anyway
 only after the entire suspend/hibernation sequence is complete.
 So, to summarize, use [un]lock_system_sleep() instead of directly using
 mutex_[un]lock(&pm_mutex). That would prevent freezing failures.
+
+V. Miscellaneous
+/sys/power/pm_freeze_timeout controls how long it will cost at most to freeze
+all user space processes or all freezable kernel threads, in unit of millisecond.
+The default value is 20000, with range of unsigned integer.
diff --git a/drivers/base/power/wakeup.c b/drivers/base/power/wakeup.c
index 1c0aa9b..c52331a 100644
--- a/drivers/base/power/wakeup.c
+++ b/drivers/base/power/wakeup.c
@@ -682,24 +682,32 @@ bool pm_wakeup_pending(void)
 /**
  * pm_get_wakeup_count - Read the number of registered wakeup events.
  * @count: Address to store the value at.
+ * @block: Whether or not to block.
  *
- * Store the number of registered wakeup events at the address in @count.  Block
- * if the current number of wakeup events being processed is nonzero.
+ * Store the number of registered wakeup events at the address in @count.  If
+ * @block is set, block until the current number of wakeup events being
+ * processed is zero.
  *
- * Return 'false' if the wait for the number of wakeup events being processed to
- * drop down to zero has been interrupted by a signal (and the current number
- * of wakeup events being processed is still nonzero).  Otherwise return 'true'.
+ * Return 'false' if the current number of wakeup events being processed is
+ * nonzero.  Otherwise return 'true'.
  */
-bool pm_get_wakeup_count(unsigned int *count)
+bool pm_get_wakeup_count(unsigned int *count, bool block)
 {
 	unsigned int cnt, inpr;
 
-	for (;;) {
-		split_counters(&cnt, &inpr);
-		if (inpr == 0 || signal_pending(current))
-			break;
-		pm_wakeup_update_hit_counts();
-		schedule_timeout_interruptible(msecs_to_jiffies(TIMEOUT));
+	if (block) {
+		DEFINE_WAIT(wait);
+
+		for (;;) {
+			prepare_to_wait(&wakeup_count_wait_queue, &wait,
+					TASK_INTERRUPTIBLE);
+			split_counters(&cnt, &inpr);
+			if (inpr == 0 || signal_pending(current))
+				break;
+
+			schedule();
+		}
+		finish_wait(&wakeup_count_wait_queue, &wait);
 	}
 
 	split_counters(&cnt, &inpr);
diff --git a/fs/cifs/transport.c b/fs/cifs/transport.c
index c50f4bf..1bffd67 100644
--- a/fs/cifs/transport.c
+++ b/fs/cifs/transport.c
@@ -340,7 +340,7 @@ wait_for_response(struct TCP_Server_Info *server, struct mid_q_entry *midQ)
 {
 	int error;
 
-	error = wait_event_freezekillable(server->response_q,
+	error = wait_event_freezekillable_unsafe(server->response_q,
 				    midQ->mid_state != MID_REQUEST_SUBMITTED);
 	if (error < 0)
 		return -ERESTARTSYS;
diff --git a/fs/nfs/inode.c b/fs/nfs/inode.c
index a6d5905..6064250 100644
--- a/fs/nfs/inode.c
+++ b/fs/nfs/inode.c
@@ -79,7 +79,7 @@ int nfs_wait_bit_killable(void *word)
 {
 	if (fatal_signal_pending(current))
 		return -ERESTARTSYS;
-	freezable_schedule();
+	freezable_schedule_unsafe();
 	return 0;
 }
 
diff --git a/fs/nfs/nfs3proc.c b/fs/nfs/nfs3proc.c
index 51017ba..5e652f4 100644
--- a/fs/nfs/nfs3proc.c
+++ b/fs/nfs/nfs3proc.c
@@ -33,7 +33,7 @@ nfs3_rpc_wrapper(struct rpc_clnt *clnt, struct rpc_message *msg, int flags)
 		res = rpc_call_sync(clnt, msg, flags);
 		if (res != -EJUKEBOX)
 			break;
-		freezable_schedule_timeout_killable(NFS_JUKEBOX_RETRY_TIME);
+		freezable_schedule_timeout_killable_unsafe(NFS_JUKEBOX_RETRY_TIME);
 		res = -ERESTARTSYS;
 	} while (!fatal_signal_pending(current));
 	return res;
diff --git a/fs/nfs/nfs4proc.c b/fs/nfs/nfs4proc.c
index 92eff4d..119839f 100644
--- a/fs/nfs/nfs4proc.c
+++ b/fs/nfs/nfs4proc.c
@@ -250,7 +250,7 @@ static int nfs4_delay(struct rpc_clnt *clnt, long *timeout)
 		*timeout = NFS4_POLL_RETRY_MIN;
 	if (*timeout > NFS4_POLL_RETRY_MAX)
 		*timeout = NFS4_POLL_RETRY_MAX;
-	freezable_schedule_timeout_killable(*timeout);
+	freezable_schedule_timeout_killable_unsafe(*timeout);
 	if (fatal_signal_pending(current))
 		res = -ERESTARTSYS;
 	*timeout <<= 1;
@@ -4198,7 +4198,7 @@ int nfs4_proc_delegreturn(struct inode *inode, struct rpc_cred *cred, const nfs4
 static unsigned long
 nfs4_set_lock_task_retry(unsigned long timeout)
 {
-	freezable_schedule_timeout_killable(timeout);
+	freezable_schedule_timeout_killable_unsafe(timeout);
 	timeout <<= 1;
 	if (timeout > NFS4_LOCK_MAXTIMEOUT)
 		return NFS4_LOCK_MAXTIMEOUT;
diff --git a/include/linux/freezer.h b/include/linux/freezer.h
index eec93fc..1b6b4b1 100644
--- a/include/linux/freezer.h
+++ b/include/linux/freezer.h
@@ -3,6 +3,7 @@
 #ifndef FREEZER_H_INCLUDED
 #define FREEZER_H_INCLUDED
 
+#include <linux/debug_locks.h>
 #include <linux/sched.h>
 #include <linux/wait.h>
 #include <linux/atomic.h>
@@ -13,6 +14,11 @@ extern bool pm_freezing;		/* PM freezing in effect */
 extern bool pm_nosig_freezing;		/* PM nosig freezing in effect */
 
 /*
+ * Timeout for stopping processes
+ */
+extern unsigned int freeze_timeout_msecs;
+
+/*
  * Check if a process has been frozen
  */
 static inline bool frozen(struct task_struct *p)
@@ -52,17 +58,25 @@ static inline bool try_to_freeze_nowarn(void)
 	return __refrigerator(false);
 }
 
-static inline bool try_to_freeze(void)
-{
-/* This causes problems for ARM targets and is a known
- * problem upstream.
- *	might_sleep();
+/*
+ * DO NOT ADD ANY NEW CALLERS OF THIS FUNCTION
+ * If try_to_freeze causes a lockdep warning it means the caller may deadlock
  */
+static inline bool try_to_freeze_unsafe(void)
+{
+	might_sleep();
 	if (likely(!freezing(current)))
 		return false;
 	return __refrigerator(false);
 }
 
+static inline bool try_to_freeze(void)
+{
+	if (!(current->flags & PF_NOFREEZE))
+		debug_check_no_locks_held();
+	return try_to_freeze_unsafe();
+}
+
 extern bool freeze_task(struct task_struct *p);
 extern bool set_freezable(void);
 
@@ -124,6 +138,14 @@ static inline void freezer_count(void)
 	try_to_freeze();
 }
 
+/* DO NOT ADD ANY NEW CALLERS OF THIS FUNCTION */
+static inline void freezer_count_unsafe(void)
+{
+	current->flags &= ~PF_FREEZER_SKIP;
+	smp_mb();
+	try_to_freeze_unsafe();
+}
+
 /**
  * freezer_should_skip - whether to skip a task when determining frozen
  *			 state is reached
@@ -155,12 +177,12 @@ static inline bool freezer_should_skip(struct task_struct *p)
  */
 
 /* Like schedule(), but should not block the freezer. */
-#define freezable_schedule()						\
-({									\
-	freezer_do_not_count();						\
-	schedule();							\
-	freezer_count();						\
-})
+static inline void freezable_schedule(void)
+{
+	freezer_do_not_count();
+	schedule();
+	freezer_count();
+}
 
 /* Like schedule_timeout(), but should not block the freezer. */
 #define freezable_schedule_timeout(timeout)				\
@@ -182,15 +204,49 @@ static inline bool freezer_should_skip(struct task_struct *p)
 	__retval;							\
 })
 
+/* DO NOT ADD ANY NEW CALLERS OF THIS FUNCTION */
+static inline void freezable_schedule_unsafe(void)
+{
+	freezer_do_not_count();
+	schedule();
+	freezer_count_unsafe();
+}
+
+/*
+ * Like freezable_schedule_timeout(), but should not block the freezer.  Do not
+ * call this with locks held.
+ */
+static inline long freezable_schedule_timeout(long timeout)
+{
+	long __retval;
+	freezer_do_not_count();
+	__retval = schedule_timeout(timeout);
+	freezer_count();
+	return __retval;
+}
+
+/*
+ * Like schedule_timeout_interruptible(), but should not block the freezer.  Do not
+ * call this with locks held.
+ */
+static inline long freezable_schedule_timeout_interruptible(long timeout)
+{
+	long __retval;
+	freezer_do_not_count();
+	__retval = schedule_timeout_interruptible(timeout);
+	freezer_count();
+	return __retval;
+}
+
 /* Like schedule_timeout_killable(), but should not block the freezer. */
-#define freezable_schedule_timeout_killable(timeout)			\
-({									\
-	long __retval;							\
-	freezer_do_not_count();						\
-	__retval = schedule_timeout_killable(timeout);			\
-	freezer_count();						\
-	__retval;							\
-})
+static inline long freezable_schedule_timeout_killable(long timeout)
+{
+	long __retval;
+	freezer_do_not_count();
+	__retval = schedule_timeout_killable(timeout);
+	freezer_count();
+	return __retval;
+}
 
 /* Like schedule_hrtimeout_range(), but should not block the freezer. */
 #define freezable_schedule_hrtimeout_range(expires, delta, mode)	\
@@ -202,6 +258,30 @@ static inline bool freezer_should_skip(struct task_struct *p)
 	__retval;							\
 })
 
+/* DO NOT ADD ANY NEW CALLERS OF THIS FUNCTION */
+static inline long freezable_schedule_timeout_killable_unsafe(long timeout)
+{
+	long __retval;
+	freezer_do_not_count();
+	__retval = schedule_timeout_killable(timeout);
+	freezer_count_unsafe();
+	return __retval;
+}
+
+/*
+ * Like schedule_hrtimeout_range(), but should not block the freezer.  Do not
+ * call this with locks held.
+ */
+static inline int freezable_schedule_hrtimeout_range(ktime_t *expires,
+		unsigned long delta, const enum hrtimer_mode mode)
+{
+	int __retval;
+	freezer_do_not_count();
+	__retval = schedule_hrtimeout_range(expires, delta, mode);
+	freezer_count();
+	return __retval;
+}
+
 /*
  * Freezer-friendly wrappers around wait_event_interruptible(),
  * wait_event_killable() and wait_event_interruptible_timeout(), originally
@@ -217,6 +297,16 @@ static inline bool freezer_should_skip(struct task_struct *p)
 	__retval;							\
 })
 
+/* DO NOT ADD ANY NEW CALLERS OF THIS FUNCTION */
+#define wait_event_freezekillable_unsafe(wq, condition)			\
+({									\
+	int __retval;							\
+	freezer_do_not_count();						\
+	__retval = wait_event_killable(wq, (condition));		\
+	freezer_count_unsafe();						\
+	__retval;							\
+})
+
 #define wait_event_freezable(wq, condition)				\
 ({									\
 	int __retval;							\
@@ -245,6 +335,16 @@ static inline bool freezer_should_skip(struct task_struct *p)
 	__retval;							\
 })
 
+#define wait_event_freezable_exclusive(wq, condition)			\
+({									\
+	int __retval;							\
+	freezer_do_not_count();						\
+	__retval = wait_event_interruptible_exclusive(wq, condition);	\
+	freezer_count();						\
+	__retval;							\
+})
+
+
 #else /* !CONFIG_FREEZER */
 static inline bool frozen(struct task_struct *p) { return false; }
 static inline bool freezing(struct task_struct *p) { return false; }
@@ -265,6 +365,8 @@ static inline void set_freezable(void) {}
 
 #define freezable_schedule()  schedule()
 
+#define freezable_schedule_unsafe()  schedule(
+
 #define freezable_schedule_timeout(timeout)  schedule_timeout(timeout)
 
 #define freezable_schedule_timeout_interruptible(timeout)		\
@@ -274,6 +376,9 @@ static inline void set_freezable(void) {}
 #define freezable_schedule_timeout_killable(timeout)			\
 	schedule_timeout_killable(timeout)
 
+#define freezable_schedule_timeout_killable_unsafe(timeout)		\
+	schedule_timeout_killable(timeout)
+
 #define freezable_schedule_hrtimeout_range(expires, delta, mode)	\
 	schedule_hrtimeout_range(expires, delta, mode)
 
@@ -289,6 +394,9 @@ static inline void set_freezable(void) {}
 #define wait_event_freezekillable(wq, condition)		\
 		wait_event_killable(wq, condition)
 
+#define wait_event_freezekillable_unsafe(wq, condition)			\
+		wait_event_killable(wq, condition)
+
 #endif /* !CONFIG_FREEZER */
 
 #endif	/* FREEZER_H_INCLUDED */
diff --git a/include/linux/sched.h b/include/linux/sched.h
index 5b66399..923e30e 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -1861,6 +1861,7 @@ extern int task_free_unregister(struct notifier_block *n);
 #define PF_MEMPOLICY	0x10000000	/* Non-default NUMA mempolicy */
 #define PF_MUTEX_TESTER	0x20000000	/* Thread belongs to the rt mutex tester */
 #define PF_FREEZER_SKIP	0x40000000	/* Freezer should not count it as freezable */
+#define PF_SUSPEND_TASK 0x80000000	/* this thread called freeze_processes and should not be frozen */
 
 /*
  * Only the _current_ task can read/write to tsk->flags, but other
diff --git a/include/linux/suspend.h b/include/linux/suspend.h
index debefda..39344a3 100644
--- a/include/linux/suspend.h
+++ b/include/linux/suspend.h
@@ -357,7 +357,7 @@ extern int unregister_pm_notifier(struct notifier_block *nb);
 extern bool events_check_enabled;
 
 extern bool pm_wakeup_pending(void);
-extern bool pm_get_wakeup_count(unsigned int *count);
+extern bool pm_get_wakeup_count(unsigned int *count, bool block);
 extern bool pm_save_wakeup_count(unsigned int count);
 
 static inline void lock_system_sleep(void)
@@ -408,6 +408,17 @@ static inline void unlock_system_sleep(void) {}
 
 #endif /* !CONFIG_PM_SLEEP */
 
+#ifdef CONFIG_PM_AUTOSLEEP
+
+/* kernel/power/autosleep.c */
+void queue_up_suspend_work(void);
+
+#else /* !CONFIG_PM_AUTOSLEEP */
+
+static inline void queue_up_suspend_work(void) {}
+
+#endif /* !CONFIG_PM_AUTOSLEEP */
+
 #ifdef CONFIG_ARCH_SAVE_PAGE_KEYS
 /*
  * The ARCH_SAVE_PAGE_KEYS functions can be used by an architecture
diff --git a/kernel/exit.c b/kernel/exit.c
index 07cfad6..f7ad930 100644
--- a/kernel/exit.c
+++ b/kernel/exit.c
@@ -20,6 +20,7 @@
 #include <linux/tsacct_kern.h>
 #include <linux/file.h>
 #include <linux/fdtable.h>
+#include <linux/freezer.h>
 #include <linux/binfmts.h>
 #include <linux/nsproxy.h>
 #include <linux/pid_namespace.h>
@@ -31,7 +32,6 @@
 #include <linux/mempolicy.h>
 #include <linux/taskstats_kern.h>
 #include <linux/delayacct.h>
-#include <linux/freezer.h>
 #include <linux/cgroup.h>
 #include <linux/syscalls.h>
 #include <linux/signal.h>
@@ -672,7 +672,7 @@ static void exit_mm(struct task_struct * tsk)
 			set_task_state(tsk, TASK_UNINTERRUPTIBLE);
 			if (!self.task) /* see coredump_finish() */
 				break;
-			schedule();
+			freezable_schedule();
 		}
 		__set_task_state(tsk, TASK_RUNNING);
 		down_read(&mm->mmap_sem);
diff --git a/kernel/freezer.c b/kernel/freezer.c
index df6fc77..90d3286 100644
--- a/kernel/freezer.c
+++ b/kernel/freezer.c
@@ -33,7 +33,7 @@ static DEFINE_SPINLOCK(freezer_lock);
  */
 bool freezing_slow_path(struct task_struct *p)
 {
-	if (p->flags & PF_NOFREEZE)
+	if (p->flags & (PF_NOFREEZE | PF_SUSPEND_TASK))
 		return false;
 
 	if (test_thread_flag(TIF_MEMDIE))
diff --git a/kernel/power/Kconfig b/kernel/power/Kconfig
index 91ce297..18fcd02 100755
--- a/kernel/power/Kconfig
+++ b/kernel/power/Kconfig
@@ -171,6 +171,14 @@ config PM_SLEEP_SMP
 	select HOTPLUG
 	select HOTPLUG_CPU
 
+config PM_AUTOSLEEP
+	bool "Opportunistic sleep"
+	depends on PM_SLEEP
+	default n
+	---help---
+	Allow the kernel to trigger a system transition into a global sleep
+	state automatically whenever there are no active wakeup sources.
+
 config PM_RUNTIME
 	bool "Run-time PM core functionality"
 	depends on !IA64_HP_SIM
diff --git a/kernel/power/Makefile b/kernel/power/Makefile
index dcc3be9..81c976d 100755
--- a/kernel/power/Makefile
+++ b/kernel/power/Makefile
@@ -9,6 +9,7 @@ obj-$(CONFIG_SUSPEND)		+= suspend.o
 obj-$(CONFIG_PM_TEST_SUSPEND)	+= suspend_test.o
 obj-$(CONFIG_HIBERNATION)	+= hibernate.o snapshot.o swap.o user.o \
 				   block_io.o
+obj-$(CONFIG_PM_AUTOSLEEP)	+= autosleep.o
 obj-$(CONFIG_WAKELOCK)		+= wakelock.o
 obj-$(CONFIG_USER_WAKELOCK)	+= userwakelock.o
 obj-$(CONFIG_EARLYSUSPEND)	+= earlysuspend.o
diff --git a/kernel/power/autosleep.c b/kernel/power/autosleep.c
new file mode 100644
index 0000000..42348e3
--- /dev/null
+++ b/kernel/power/autosleep.c
@@ -0,0 +1,123 @@
+/*
+ * kernel/power/autosleep.c
+ *
+ * Opportunistic sleep support.
+ *
+ * Copyright (C) 2012 Rafael J. Wysocki <rjw@sisk.pl>
+ */
+
+#include <linux/device.h>
+#include <linux/mutex.h>
+#include <linux/pm_wakeup.h>
+
+#include "power.h"
+
+static suspend_state_t autosleep_state;
+static struct workqueue_struct *autosleep_wq;
+/*
+ * Note: it is only safe to mutex_lock(&autosleep_lock) if a wakeup_source
+ * is active, otherwise a deadlock with try_to_suspend() is possible.
+ * Alternatively mutex_lock_interruptible() can be used.  This will then fail
+ * if an auto_sleep cycle tries to freeze processes.
+ */
+static DEFINE_MUTEX(autosleep_lock);
+static struct wakeup_source *autosleep_ws;
+
+static void try_to_suspend(struct work_struct *work)
+{
+	unsigned int initial_count, final_count;
+
+	if (!pm_get_wakeup_count(&initial_count, true))
+		goto out;
+
+	mutex_lock(&autosleep_lock);
+
+	if (!pm_save_wakeup_count(initial_count)) {
+		mutex_unlock(&autosleep_lock);
+		goto out;
+	}
+
+	if (autosleep_state == PM_SUSPEND_ON) {
+		mutex_unlock(&autosleep_lock);
+		return;
+	}
+	if (autosleep_state >= PM_SUSPEND_MAX)
+		hibernate();
+	else
+		pm_suspend(autosleep_state);
+
+	mutex_unlock(&autosleep_lock);
+
+	if (!pm_get_wakeup_count(&final_count, false))
+		goto out;
+
+	/*
+	 * If the wakeup occured for an unknown reason, wait to prevent the
+	 * system from trying to suspend and waking up in a tight loop.
+	 */
+	if (final_count == initial_count)
+		schedule_timeout_uninterruptible(HZ / 2);
+
+ out:
+	queue_up_suspend_work();
+}
+
+static DECLARE_WORK(suspend_work, try_to_suspend);
+
+void queue_up_suspend_work(void)
+{
+	if (!work_pending(&suspend_work) && autosleep_state > PM_SUSPEND_ON)
+		queue_work(autosleep_wq, &suspend_work);
+}
+
+suspend_state_t pm_autosleep_state(void)
+{
+	return autosleep_state;
+}
+
+int pm_autosleep_lock(void)
+{
+	return mutex_lock_interruptible(&autosleep_lock);
+}
+
+void pm_autosleep_unlock(void)
+{
+	mutex_unlock(&autosleep_lock);
+}
+
+int pm_autosleep_set_state(suspend_state_t state)
+{
+
+#ifndef CONFIG_HIBERNATION
+	if (state >= PM_SUSPEND_MAX)
+		return -EINVAL;
+#endif
+
+	__pm_stay_awake(autosleep_ws);
+
+	mutex_lock(&autosleep_lock);
+
+	autosleep_state = state;
+
+	__pm_relax(autosleep_ws);
+
+	if (state > PM_SUSPEND_ON)
+		queue_up_suspend_work();
+
+	mutex_unlock(&autosleep_lock);
+	return 0;
+}
+
+int __init pm_autosleep_init(void)
+{
+	autosleep_ws = wakeup_source_register("autosleep");
+	if (!autosleep_ws)
+		return -ENOMEM;
+
+	autosleep_wq = alloc_ordered_workqueue("autosleep", 0);
+	if (autosleep_wq)
+		return 0;
+
+	wakeup_source_unregister(autosleep_ws);
+	return -ENOMEM;
+}
diff --git a/kernel/power/main.c b/kernel/power/main.c
index 646f347..f3303a5 100644
--- a/kernel/power/main.c
+++ b/kernel/power/main.c
@@ -361,47 +361,56 @@ static ssize_t state_show(struct kobject *kobj, struct kobj_attribute *attr,
 	return (s - buf);
 }
 
-static ssize_t state_store(struct kobject *kobj, struct kobj_attribute *attr,
-			   const char *buf, size_t n)
+static suspend_state_t decode_state(const char *buf, size_t n)
 {
 #ifdef CONFIG_SUSPEND
-#ifdef CONFIG_EARLYSUSPEND
-	suspend_state_t state = PM_SUSPEND_ON;
-#else
 	suspend_state_t state = PM_SUSPEND_STANDBY;
-#endif
 	const char * const *s;
 #endif
 	char *p;
 	int len;
-	int error = -EINVAL;
 
 	p = memchr(buf, '\n', n);
 	len = p ? p - buf : n;
 
-	/* First, check if we are requested to hibernate */
-	if (len == 4 && !strncmp(buf, "disk", len)) {
-		error = hibernate();
-		goto Exit;
-	}
+	/* Check hibernation first. */
+	if (len == 4 && !strncmp(buf, "disk", len))
+		return PM_SUSPEND_MAX;
 
 #ifdef CONFIG_SUSPEND
-	for (s = &pm_states[state]; state < PM_SUSPEND_MAX; s++, state++) {
-		if (*s && len == strlen(*s) && !strncmp(buf, *s, len)) {
-#ifdef CONFIG_EARLYSUSPEND
-			if (state == PM_SUSPEND_ON || valid_state(state)) {
-				error = 0;
-				request_suspend_state(state);
-				break;
-			}
-#else
-			error = pm_suspend(state);
+	for (s = &pm_states[state]; state < PM_SUSPEND_MAX; s++, state++)
+		if (*s && len == strlen(*s) && !strncmp(buf, *s, len))
+			return state;
 #endif
-		}
+
+	return PM_SUSPEND_ON;
+}
+
+static ssize_t state_store(struct kobject *kobj, struct kobj_attribute *attr,
+			   const char *buf, size_t n)
+{
+	suspend_state_t state;
+	int error;
+
+	error = pm_autosleep_lock();
+	if (error)
+		return error;
+
+	if (pm_autosleep_state() > PM_SUSPEND_ON) {
+		error = -EBUSY;
+		goto out;
 	}
-#endif
 
- Exit:
+	state = decode_state(buf, n);
+	if (state < PM_SUSPEND_MAX)
+		error = pm_suspend(state);
+	else if (state == PM_SUSPEND_MAX)
+		error = hibernate();
+	else
+		error = -EINVAL;
+
+ out:
+	pm_autosleep_unlock();
 	return error ? error : n;
 }
 
@@ -442,7 +451,8 @@ static ssize_t wakeup_count_show(struct kobject *kobj,
 {
 	unsigned int val;
 
-	return pm_get_wakeup_count(&val) ? sprintf(buf, "%u\n", val) : -EINTR;
+	return pm_get_wakeup_count(&val, true) ?
+		sprintf(buf, "%u\n", val) : -EINTR;
 }
 
 static ssize_t wakeup_count_store(struct kobject *kobj,
@@ -450,15 +460,69 @@ static ssize_t wakeup_count_store(struct kobject *kobj,
 				const char *buf, size_t n)
 {
 	unsigned int val;
+	int error;
 
+	error = pm_autosleep_lock();
+	if (error)
+		return error;
+
+	if (pm_autosleep_state() > PM_SUSPEND_ON) {
+		error = -EBUSY;
+		goto out;
+	}
+
+	error = -EINVAL;
 	if (sscanf(buf, "%u", &val) == 1) {
 		if (pm_save_wakeup_count(val))
-			return n;
+			error = n;
 	}
-	return -EINVAL;
+
+ out:
+	pm_autosleep_unlock();
+	return error;
 }
 
 power_attr(wakeup_count);
+
+#ifdef CONFIG_PM_AUTOSLEEP
+static ssize_t autosleep_show(struct kobject *kobj,
+			      struct kobj_attribute *attr,
+			      char *buf)
+{
+	suspend_state_t state = pm_autosleep_state();
+
+	if (state == PM_SUSPEND_ON)
+		return sprintf(buf, "off\n");
+
+#ifdef CONFIG_SUSPEND
+	if (state < PM_SUSPEND_MAX)
+		return sprintf(buf, "%s\n", valid_state(state) ?
+						pm_states[state] : "error");
+#endif
+#ifdef CONFIG_HIBERNATION
+	return sprintf(buf, "disk\n");
+#else
+	return sprintf(buf, "error");
+#endif
+}
+
+static ssize_t autosleep_store(struct kobject *kobj,
+			       struct kobj_attribute *attr,
+			       const char *buf, size_t n)
+{
+	suspend_state_t state = decode_state(buf, n);
+	int error;
+
+	if (state == PM_SUSPEND_ON
+	    && !(strncmp(buf, "off", 3) && strncmp(buf, "off\n", 4)))
+		return -EINVAL;
+
+	error = pm_autosleep_set_state(state);
+	return error ? error : n;
+}
+
+power_attr(autosleep);
+#endif /* CONFIG_PM_AUTOSLEEP */
 #endif /* CONFIG_PM_SLEEP */
 
 #ifdef CONFIG_PM_TRACE
@@ -508,6 +572,30 @@ power_attr(wake_lock);
 power_attr(wake_unlock);
 #endif
 
+#ifdef CONFIG_FREEZER
+static ssize_t pm_freeze_timeout_show(struct kobject *kobj,
+				      struct kobj_attribute *attr, char *buf)
+{
+	return sprintf(buf, "%u\n", freeze_timeout_msecs);
+}
+
+static ssize_t pm_freeze_timeout_store(struct kobject *kobj,
+				       struct kobj_attribute *attr,
+				       const char *buf, size_t n)
+{
+	unsigned long val;
+
+	if (kstrtoul(buf, 10, &val))
+		return -EINVAL;
+
+	freeze_timeout_msecs = val;
+	return n;
+}
+
+power_attr(pm_freeze_timeout);
+
+#endif	/* CONFIG_FREEZER*/
+
 #ifdef CONFIG_SEC_DVFS
 DEFINE_MUTEX(dvfs_mutex);
 static unsigned long dvfs_id;
@@ -759,6 +847,9 @@ static struct attribute *g[] = {
 	&wakeup_count_attr.attr,
 	&touch_event_attr.attr,
 	&touch_event_timer_attr.attr,
+#ifdef CONFIG_PM_AUTOSLEEP
+	&autosleep_attr.attr,
+#endif
 #ifdef CONFIG_PM_DEBUG
 	&pm_test_attr.attr,
 #endif
@@ -767,6 +858,9 @@ static struct attribute *g[] = {
 	&wake_unlock_attr.attr,
 #endif
 #endif
+#ifdef CONFIG_FREEZER
+	&pm_freeze_timeout_attr.attr,
+#endif
 #ifdef CONFIG_SEC_DVFS
 	&cpufreq_min_limit_attr.attr,
 	&cpufreq_max_limit_attr.attr,
@@ -811,7 +905,10 @@ static int __init pm_init(void)
 	power_kobj = kobject_create_and_add("power", NULL);
 	if (!power_kobj)
 		return -ENOMEM;
-
+	error = sysfs_create_group(power_kobj, &attr_group);
+	if (error)
+		return error;
+	return pm_autosleep_init();
 #ifdef CONFIG_SEC_DVFS
 	apps_min_freq = MIN_FREQ_LIMIT;
 	apps_max_freq = MAX_FREQ_LIMIT;
diff --git a/kernel/power/power.h b/kernel/power/power.h
index f70a2db..694911d 100644
--- a/kernel/power/power.h
+++ b/kernel/power/power.h
@@ -300,3 +300,21 @@ ssize_t  wake_unlock_store(struct kobject *kobj, struct kobj_attribute *attr,
 void request_suspend_state(suspend_state_t state);
 suspend_state_t get_suspend_state(void);
 #endif
+
+#ifdef CONFIG_PM_AUTOSLEEP
+
+/* kernel/power/autosleep.c */
+extern int pm_autosleep_init(void);
+extern int pm_autosleep_lock(void);
+extern void pm_autosleep_unlock(void);
+extern suspend_state_t pm_autosleep_state(void);
+extern int pm_autosleep_set_state(suspend_state_t state);
+
+#else /* !CONFIG_PM_AUTOSLEEP */
+
+static inline int pm_autosleep_init(void) { return 0; }
+static inline int pm_autosleep_lock(void) { return 0; }
+static inline void pm_autosleep_unlock(void) {}
+static inline suspend_state_t pm_autosleep_state(void) { return PM_SUSPEND_ON; }
+
+#endif /* !CONFIG_PM_AUTOSLEEP */
diff --git a/kernel/power/process.c b/kernel/power/process.c
index 3cadf71..7608c26 100644
--- a/kernel/power/process.c
+++ b/kernel/power/process.c
@@ -40,7 +40,7 @@ static int try_to_freeze_tasks(bool user_only)
 
 	do_gettimeofday(&start);
 
-	end_time = jiffies + TIMEOUT;
+	end_time = jiffies + msecs_to_jiffies(freeze_timeout_msecs);
 
 	if (!user_only)
 		freeze_workqueues_begin();
@@ -173,6 +173,9 @@ int freeze_processes(void)
 	if (error)
 		return error;
 
+	/* Make sure this task doesn't get frozen */
+	current->flags |= PF_SUSPEND_TASK;
+
 	if (!pm_freezing)
 		atomic_inc(&system_freezing_cnt);
 
@@ -240,6 +243,7 @@ int freeze_kernel_threads(void)
 void thaw_processes(void)
 {
 	struct task_struct *g, *p;
+	struct task_struct *curr = current;
 
 	if (pm_freezing)
 		atomic_dec(&system_freezing_cnt);
@@ -255,10 +259,15 @@ void thaw_processes(void)
 
 	read_lock(&tasklist_lock);
 	do_each_thread(g, p) {
+		/* No other threads should have PF_SUSPEND_TASK set */
+		WARN_ON((p != curr) && (p->flags & PF_SUSPEND_TASK));
 		__thaw_task(p);
 	} while_each_thread(g, p);
 	read_unlock(&tasklist_lock);
 
+	WARN_ON(!(curr->flags & PF_SUSPEND_TASK));
+	curr->flags &= ~PF_SUSPEND_TASK;
+
 	usermodehelper_enable();
 
 	schedule();
diff --git a/mm/fremap.c b/mm/fremap.c
index 9ed4fd4..6013ab1 100644
--- a/mm/fremap.c
+++ b/mm/fremap.c
@@ -1,6 +1,6 @@
 /*
  *   linux/mm/fremap.c
- * 
+ *
  * Explicit pagetable population and nonlinear (random) mappings support.
  *
  * started by Ingo Molnar, Copyright (C) 2002, 2003
@@ -127,6 +127,7 @@ SYSCALL_DEFINE5(remap_file_pages, unsigned long, start, unsigned long, size,
 	struct vm_area_struct *vma;
 	int err = -EINVAL;
 	int has_write_lock = 0;
+	vm_flags_t vm_flags;
 
 	if (prot)
 		return err;
@@ -223,28 +224,14 @@ SYSCALL_DEFINE5(remap_file_pages, unsigned long, start, unsigned long, size,
 		/*
 		 * drop PG_Mlocked flag for over-mapped range
 		 */
-		vm_flags_t saved_flags = vma->vm_flags;
+		vm_flags = vma->vm_flags;
 		munlock_vma_pages_range(vma, start, start + size);
-		vma->vm_flags = saved_flags;
+		vma->vm_flags = vm_flags;
 	}
 
 	mmu_notifier_invalidate_range_start(mm, start, start + size);
 	err = populate_range(mm, vma, start, size, pgoff);
 	mmu_notifier_invalidate_range_end(mm, start, start + size);
-	if (!err && !(flags & MAP_NONBLOCK)) {
-		if (vma->vm_flags & VM_LOCKED) {
-			/*
-			 * might be mapping previously unmapped range of file
-			 */
-			mlock_vma_pages_range(vma, start, start + size);
-		} else {
-			if (unlikely(has_write_lock)) {
-				downgrade_write(&mm->mmap_sem);
-				has_write_lock = 0;
-			}
-			make_pages_present(start, start+size);
-		}
-	}
 
 	/*
 	 * We can't clear VM_NONLINEAR because we'd have to do
@@ -253,10 +240,13 @@ SYSCALL_DEFINE5(remap_file_pages, unsigned long, start, unsigned long, size,
 	 */
 
 out:
+	vm_flags = vma->vm_flags;
 	if (likely(!has_write_lock))
 		up_read(&mm->mmap_sem);
 	else
 		up_write(&mm->mmap_sem);
+	if (!err && ((vm_flags & VM_LOCKED) || !(flags & MAP_NONBLOCK)))
+		mm_populate(start, size);
 
 	return err;
 }
diff --git a/mm/vmscan.c b/mm/vmscan.c
index 667cbba..1bfaa05 100644
--- a/mm/vmscan.c
+++ b/mm/vmscan.c
@@ -1669,6 +1669,7 @@ shrink_inactive_list(unsigned long nr_to_scan, struct mem_cgroup_zone *mz,
 	 *                     isolated page is PageWriteback
 	 */
 	if (nr_writeback && nr_writeback >= (nr_taken >> (DEF_PRIORITY-priority)))
+		zone_set_flag(zone, ZONE_WRITEBACK);
 		wait_iff_congested(zone, BLK_RW_ASYNC, HZ/10);
 
 #ifdef CONFIG_RUNTIME_COMPCACHE
@@ -3197,7 +3198,7 @@ static int kswapd(void *p)
 	classzone_idx = new_classzone_idx = pgdat->nr_zones - 1;
 	balanced_classzone_idx = classzone_idx;
 	for ( ; ; ) {
-		int ret;
+		bool ret;
 
 		/*
 		 * If the last balance_pgdat was unsuccessful it's unlikely a
diff --git a/net/sunrpc/sched.c b/net/sunrpc/sched.c
index c393017..b50336b 100644
--- a/net/sunrpc/sched.c
+++ b/net/sunrpc/sched.c
@@ -235,7 +235,7 @@ static int rpc_wait_bit_killable(void *word)
 {
 	if (fatal_signal_pending(current))
 		return -ERESTARTSYS;
-	freezable_schedule();
+	freezable_schedule_unsafe();
 	return 0;
 }
 
